{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAIEnvironment created\n",
      "Namespace(dump_path='./dumped/', exp_name='first_train', save_periodic=0, exp_id='dmytro_job', fp16=False, amp=-1, emb_dim=64, bottleneck_dim=64, nn_output=1, input_seq_length=47, n_enc_layers=16, n_dec_layers=4, n_heads=4, dropout=0.1, attention_dropout=0.1, share_inout_emb=False, sinusoidal_embeddings=True, env_base_seed=0, max_len=512, batch_size=32, optimizer='adam,lr=0.0001', clip_grad_norm=5, epoch_size=10000, max_epoch=100000, stopping_criterion='', validation_metrics='', accumulate_gradients=1, num_workers=4, same_nb_ops_per_batch=False, reload_size=-1, env_name='sai', tasks='add_dataset', beam_eval=False, beam_size=1, beam_length_penalty=1, beam_early_stopping=True, reload_model='', reload_checkpoint='', eval_only=False, eval_verbose=0, eval_verbose_print=False, debug_slurm=False, debug=False, cpu=False, local_rank=-1, master_port=-1)\n",
      "SLURM job: False\n",
      "0 - Number of nodes: 1\n",
      "0 - Node ID        : 0\n",
      "0 - Local rank     : 0\n",
      "0 - Global rank    : 0\n",
      "0 - World size     : 1\n",
      "0 - GPUs per node  : 1\n",
      "0 - Master         : True\n",
      "0 - Multi-node     : False\n",
      "0 - Multi-GPU      : False\n",
      "0 - Hostname       : DESKTOP-GPBACS8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 01/06/23 12:35:59 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 01/06/23 12:35:59 - 0:00:00 - accumulate_gradients: 1\n",
      "                                     amp: -1\n",
      "                                     attention_dropout: 0.1\n",
      "                                     batch_size: 32\n",
      "                                     beam_early_stopping: True\n",
      "                                     beam_eval: False\n",
      "                                     beam_length_penalty: 1\n",
      "                                     beam_size: 1\n",
      "                                     bottleneck_dim: 64\n",
      "                                     clip_grad_norm: 5\n",
      "                                     command: python F:\\Programs\\anaconda3\\envs\\ai\\lib\\site-packages\\ipykernel_launcher.py '-f' 'C:\\Users\\Dmytro\\AppData\\Roaming\\jupyter\\runtime\\kernel-6544956e-49e2-49a1-841d-3d53f39d231b.json' --exp_id \"dmytro_job\"\n",
      "                                     cpu: False\n",
      "                                     debug: False\n",
      "                                     debug_slurm: False\n",
      "                                     dropout: 0.1\n",
      "                                     dump_path: ./dumped/\n",
      "                                     emb_dim: 64\n",
      "                                     env_base_seed: 0\n",
      "                                     env_name: sai\n",
      "                                     epoch_size: 10000\n",
      "                                     eval_only: False\n",
      "                                     eval_verbose: 0\n",
      "                                     eval_verbose_print: False\n",
      "                                     exp_id: dmytro_job\n",
      "                                     exp_name: first_train\n",
      "                                     fp16: False\n",
      "                                     global_rank: 0\n",
      "                                     input_seq_length: 47\n",
      "                                     is_master: True\n",
      "                                     is_slurm_job: False\n",
      "                                     local_rank: 0\n",
      "                                     master_port: -1\n",
      "                                     max_epoch: 100000\n",
      "                                     max_len: 512\n",
      "                                     multi_gpu: False\n",
      "                                     multi_node: False\n",
      "                                     n_dec_layers: 4\n",
      "                                     n_enc_layers: 16\n",
      "                                     n_gpu_per_node: 1\n",
      "                                     n_heads: 4\n",
      "                                     n_nodes: 1\n",
      "                                     nn_output: 1\n",
      "                                     node_id: 0\n",
      "                                     num_workers: 4\n",
      "                                     optimizer: adam,lr=0.0001\n",
      "                                     reload_checkpoint: \n",
      "                                     reload_model: \n",
      "                                     reload_size: -1\n",
      "                                     same_nb_ops_per_batch: False\n",
      "                                     save_periodic: 0\n",
      "                                     share_inout_emb: False\n",
      "                                     sinusoidal_embeddings: True\n",
      "                                     stopping_criterion: \n",
      "                                     tasks: add_dataset\n",
      "                                     validation_metrics: \n",
      "                                     world_size: 1\n",
      "INFO - 01/06/23 12:35:59 - 0:00:00 - The experiment will be stored in ./dumped/\n",
      "                                     \n",
      "INFO - 01/06/23 12:35:59 - 0:00:00 - Running command: python F:\\Programs\\anaconda3\\envs\\ai\\lib\\site-packages\\ipykernel_launcher.py '-f' 'C:\\Users\\Dmytro\\AppData\\Roaming\\jupyter\\runtime\\kernel-6544956e-49e2-49a1-841d-3d53f39d231b.json'\n",
      "\n",
      "INFO - 01/06/23 12:35:59 - 0:00:00 - words: {'<s>': 0, '</s>': 1, 'A': 2, 'B': 3, 'C': 4, 'D': 5, 'E': 6, 'F': 7, 'G': 8, 'H': 9, 'I': 10, 'J': 11, 'K': 12, 'L': 13, 'M': 14, 'N': 15, 'O': 16, 'P': 17, 'Q': 18, 'R': 19, 'S': 20, 'T': 21, 'U': 22, 'V': 23, 'W': 24, 'X': 25, 'Y': 26, 'Z': 27, '0': 28, '1': 29, '2': 30, '3': 31, '4': 32, '5': 33, '6': 34, '7': 35, '8': 36, '9': 37}\n",
      "INFO - 01/06/23 12:35:59 - 0:00:00 - Training tasks: add_dataset\n",
      "INFO - 01/06/23 12:35:59 - 0:00:00 - Number of parameters (transformer): 1598630\n",
      "INFO - 01/06/23 12:36:00 - 0:00:00 - Found 370 parameters in model.\n",
      "INFO - 01/06/23 12:36:02 - 0:00:02 - Optimizers: model\n",
      "INFO - 01/06/23 12:36:02 - 0:00:02 - Number of parameters (transformer): 1598630\n",
      "INFO - 01/06/23 12:36:02 - 0:00:03 - Found 370 parameters in model.\n",
      "INFO - 01/06/23 12:36:04 - 0:00:04 - Optimizers: model\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import src\n",
    "from envs import build_env\n",
    "#from src.evaluator import Evaluator\n",
    "from src.slurm import init_signal_handler, init_distributed_mode\n",
    "from t2.realtime_trainer import RealtimeTrainer\n",
    "from src.utils import initialize_exp\n",
    "from t2.utils import get_parser\n",
    "\n",
    "from t2.transformer import build_transformer\n",
    "argv = [\n",
    "        '--exp_name', 'first_train', \n",
    "        '--tasks', 'add_dataset', \n",
    "        '--n_enc_layers', '16', \n",
    "        '--n_heads', '4', \n",
    "        '--sinusoidal_embeddings', 'true', \n",
    "        '--num_workers', '4', \n",
    "        '--eval_onl', '0', \n",
    "        '--save_periodic', '0', \n",
    "        '--epoch_size', '10000', \n",
    "        '--batch_size', '32', \n",
    "        '--dropout', '0.1', \n",
    "        '--attention_dropout', '0.1', \n",
    "        '--emb_dim', '64', \n",
    "        '--bottleneck_dim', '64', \n",
    "        '--nn_output', '1', \n",
    "        '--input_seq_length', '47', \n",
    "        '--share_inout_emb', 'false'\n",
    "]\n",
    "\n",
    "parser = get_parser()\n",
    "\n",
    "params = parser.parse_args(argv)\n",
    "print(params)\n",
    "\n",
    "bs = params.batch_size\n",
    "#dim = params.emb_dim\n",
    "\n",
    "init_distributed_mode(params)\n",
    "logger = initialize_exp(params)\n",
    "\n",
    "# CPU / CUDA\n",
    "if params.cpu:\n",
    "    assert not params.multi_gpu\n",
    "else:\n",
    "    assert torch.cuda.is_available()\n",
    "    \n",
    "src.utils.CUDA = not params.cpu\n",
    "\n",
    "env = build_env(params)\n",
    "\n",
    "# modules = build_transformer(env, params, 'cuda')\n",
    "# trainer = RealtimeTrainer(modules, env, params)\n",
    "\n",
    "trainers=[]\n",
    "number_of_models=2\n",
    "for i in range(number_of_models):\n",
    "    params.my_device='cuda:' + str(i)\n",
    "    trainer = RealtimeTrainer(build_transformer(env, params), env, params)\n",
    "    trainers += [trainer]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act(inp, trainer):\n",
    "    inp = join_sai(inp)\n",
    "    lst = []\n",
    "    for _ in range(bs):\n",
    "        x = inp\n",
    "        lst += [x]\n",
    "        \n",
    "    return trainer.act(lst)[0]\n",
    "\n",
    "def to_sai_str(p):\n",
    "    return join_sai(p.data)\n",
    "\n",
    "\n",
    "def join_sai(data):\n",
    "    return ' '.join(data)\n",
    "\n",
    "def str_diff(s1, s2):\n",
    "    diff = abs(len(s1) - len(s2))\n",
    "    for i in range(min(len(s1), len(s2))):\n",
    "        diff += 1 if s1[i] != s2[i] else 0\n",
    "    return diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 'KAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAE'\n",
    "a = join_sai(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\workspace\\ai\\Transformers1\\src\\optim.py:72: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\python_arg_parser.cpp:1418.)\n",
      "  exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
      "INFO - 01/06/23 12:36:06 - 0:00:07 - learning: av-score=0.06981382978723405, device=cuda:0\n",
      "INFO - 01/06/23 12:36:07 - 0:00:08 - learning: av-score=0.038563829787234036, device=cuda:1\n",
      "INFO - 01/06/23 12:36:07 - 0:00:08 - learning: av-score=0.048537234042553175, device=cuda:0\n",
      "INFO - 01/06/23 12:36:07 - 0:00:08 - learning: av-score=0.06382978723404255, device=cuda:1\n",
      "INFO - 01/06/23 12:36:08 - 0:00:08 - learning: av-score=0.36768617021276595, device=cuda:0\n",
      "INFO - 01/06/23 12:36:08 - 0:00:08 - learning: av-score=0.2200797872340425, device=cuda:1\n",
      "INFO - 01/06/23 12:36:08 - 0:00:09 - learning: av-score=0.8138297872340422, device=cuda:0\n",
      "INFO - 01/06/23 12:36:08 - 0:00:09 - learning: av-score=0.5970744680851061, device=cuda:1\n",
      "INFO - 01/06/23 12:36:08 - 0:00:09 - learning: av-score=0.9454787234042558, device=cuda:0\n",
      "INFO - 01/06/23 12:36:09 - 0:00:09 - learning: av-score=0.9062500000000003, device=cuda:1\n",
      "INFO - 01/06/23 12:36:09 - 0:00:09 - learning: av-score=0.9567819148936174, device=cuda:0\n",
      "INFO - 01/06/23 12:36:09 - 0:00:10 - learning: av-score=0.9541223404255323, device=cuda:1\n",
      "INFO - 01/06/23 12:36:09 - 0:00:10 - learning: av-score=0.9574468085106387, device=cuda:0\n",
      "INFO - 01/06/23 12:36:09 - 0:00:10 - learning: av-score=0.9574468085106387, device=cuda:1\n",
      "INFO - 01/06/23 12:36:10 - 0:00:10 - learning: av-score=0.9574468085106387, device=cuda:0\n",
      "INFO - 01/06/23 12:36:10 - 0:00:11 - learning: av-score=0.9574468085106387, device=cuda:1\n",
      "INFO - 01/06/23 12:36:10 - 0:00:11 - learning: av-score=0.9574468085106387, device=cuda:0\n",
      "INFO - 01/06/23 12:36:10 - 0:00:11 - learning: av-score=0.9574468085106387, device=cuda:1\n",
      "INFO - 01/06/23 12:36:10 - 0:00:11 - learning: av-score=0.9574468085106387, device=cuda:0\n",
      "INFO - 01/06/23 12:36:11 - 0:00:11 - learning: av-score=0.9574468085106387, device=cuda:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Av time per iteration per trainer: 0.69 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "losses = []\n",
    "iterations_number = 10\n",
    "\n",
    "for it in range(iterations_number):\n",
    "    for trainer in trainers:\n",
    "            for _ in range(params.batch_size):\n",
    "                loss = trainer.learn(a, a)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "av_time = elapsed_time/iterations_number/len(trainers)\n",
    "\n",
    "print(f'Av time per iteration per trainer: {elapsed_time/iterations_number:.2f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3080 Ti'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(next(trainers[0].modules['transformer'].te1.parameters()).device.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33908/2454445127.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#rnds = [gen_rnd_chars(xy_data_size_const) for _ in range(100)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\workspace\\ai\\Transformers1\\t2\\realtime_trainer.py\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, xx)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_act\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcollate_fn2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\workspace\\ai\\Transformers1\\t2\\abstract_trainer.py\u001b[0m in \u001b[0;36m_act\u001b[1;34m(self, x1, len1)\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;31m# forward / loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fwd'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'generate'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpred_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m         \u001b[1;31m# output = output.reshape(bs, -1, self.params.n_words)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;31m# i = random.randint(0, bs - 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Programs\\anaconda3\\envs\\ai\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\workspace\\ai\\Transformers1\\t2\\utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, mode, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'generate'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown mode: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\workspace\\ai\\Transformers1\\t2\\transformer.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, tensor, pred_mask)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_seq_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpred_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "A = 'KAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAE'\n",
    "B = 'KBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBE'\n",
    "X = 'KAAADAAAAADAAAAAMAAAAAAAAAAASAAAALAAAAAFNAAZE'\n",
    "\n",
    "#rnds = [gen_rnd_chars(xy_data_size_const) for _ in range(100)]\n",
    "\n",
    "print(trainers[0].act(A))\n",
    "print(trainers[0].act(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A = 'KAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAE'\n",
    "B = 'KBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBE'\n",
    "X = 'KAAADAAAAADAAAAAMAAAAAAAAAAASAAAALAAAAAFNAAZE'\n",
    "\n",
    "losses = []\n",
    "for it in range(2000):\n",
    "    loss = trainer.learn(join_sai(A), join_sai(A))\n",
    "    if loss[0]:\n",
    "        l = loss[1].item()\n",
    "        losses += [l]\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.title('los s vs iteration')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(act(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(act(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot find context for 'fork'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_38792/4223706200.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_start_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fork'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\Programs\\anaconda3\\envs\\ai\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36mset_start_method\u001b[1;34m(self, method, force)\u001b[0m\n\u001b[0;32m    245\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_actual_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_actual_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_start_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_none\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Programs\\anaconda3\\envs\\ai\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36mget_context\u001b[1;34m(self, method)\u001b[0m\n\u001b[0;32m    237\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_actual_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_start_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Programs\\anaconda3\\envs\\ai\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36mget_context\u001b[1;34m(self, method)\u001b[0m\n\u001b[0;32m    191\u001b[0m             \u001b[0mctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concrete_contexts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cannot find context for %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m         \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot find context for 'fork'"
     ]
    }
   ],
   "source": [
    "mp.set_start_method('spawn', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m():\n",
    "    while True:\n",
    "        print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = mp.Process(target=m, args=())\n",
    "\n",
    "p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
