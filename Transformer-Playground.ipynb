{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 01/05/23 22:48:20 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 01/05/23 22:48:20 - 0:00:00 - accumulate_gradients: 1\n",
      "                                     amp: -1\n",
      "                                     attention_dropout: 0.1\n",
      "                                     batch_size: 32\n",
      "                                     beam_early_stopping: True\n",
      "                                     beam_eval: False\n",
      "                                     beam_length_penalty: 1\n",
      "                                     beam_size: 1\n",
      "                                     bottleneck_dim: 64\n",
      "                                     clip_grad_norm: 5\n",
      "                                     command: python F:\\Programs\\anaconda3\\envs\\ai\\lib\\site-packages\\ipykernel_launcher.py '-f' 'C:\\Users\\Dmytro\\AppData\\Roaming\\jupyter\\runtime\\kernel-f01d6e36-580f-40d8-9223-7151741e14da.json' --exp_id \"dmytro_job\"\n",
      "                                     cpu: False\n",
      "                                     debug: False\n",
      "                                     debug_slurm: False\n",
      "                                     dropout: 0.1\n",
      "                                     dump_path: ./dumped/\n",
      "                                     emb_dim: 64\n",
      "                                     env_base_seed: 0\n",
      "                                     env_name: sai\n",
      "                                     epoch_size: 10000\n",
      "                                     eval_only: False\n",
      "                                     eval_verbose: 0\n",
      "                                     eval_verbose_print: False\n",
      "                                     exp_id: dmytro_job\n",
      "                                     exp_name: first_train\n",
      "                                     fp16: False\n",
      "                                     global_rank: 0\n",
      "                                     input_seq_length: 47\n",
      "                                     is_master: True\n",
      "                                     is_slurm_job: False\n",
      "                                     local_rank: 0\n",
      "                                     master_port: -1\n",
      "                                     max_epoch: 100000\n",
      "                                     max_len: 512\n",
      "                                     multi_gpu: False\n",
      "                                     multi_node: False\n",
      "                                     n_dec_layers: 4\n",
      "                                     n_enc_layers: 16\n",
      "                                     n_gpu_per_node: 1\n",
      "                                     n_heads: 4\n",
      "                                     n_nodes: 1\n",
      "                                     nn_output: 1\n",
      "                                     node_id: 0\n",
      "                                     num_workers: 4\n",
      "                                     optimizer: adam,lr=0.0001\n",
      "                                     reload_checkpoint: \n",
      "                                     reload_model: \n",
      "                                     reload_size: -1\n",
      "                                     same_nb_ops_per_batch: False\n",
      "                                     save_periodic: 0\n",
      "                                     share_inout_emb: False\n",
      "                                     sinusoidal_embeddings: True\n",
      "                                     stopping_criterion: \n",
      "                                     tasks: add_dataset\n",
      "                                     validation_metrics: \n",
      "                                     world_size: 1\n",
      "INFO - 01/05/23 22:48:20 - 0:00:00 - The experiment will be stored in ./dumped/\n",
      "                                     \n",
      "INFO - 01/05/23 22:48:20 - 0:00:00 - Running command: python F:\\Programs\\anaconda3\\envs\\ai\\lib\\site-packages\\ipykernel_launcher.py '-f' 'C:\\Users\\Dmytro\\AppData\\Roaming\\jupyter\\runtime\\kernel-f01d6e36-580f-40d8-9223-7151741e14da.json'\n",
      "\n",
      "INFO - 01/05/23 22:48:20 - 0:00:00 - words: {'<s>': 0, '</s>': 1, 'A': 2, 'B': 3, 'C': 4, 'D': 5, 'E': 6, 'F': 7, 'G': 8, 'H': 9, 'I': 10, 'J': 11, 'K': 12, 'L': 13, 'M': 14, 'N': 15, 'O': 16, 'P': 17, 'Q': 18, 'R': 19, 'S': 20, 'T': 21, 'U': 22, 'V': 23, 'W': 24, 'X': 25, 'Y': 26, 'Z': 27, '0': 28, '1': 29, '2': 30, '3': 31, '4': 32, '5': 33, '6': 34, '7': 35, '8': 36, '9': 37}\n",
      "INFO - 01/05/23 22:48:20 - 0:00:00 - Training tasks: add_dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAIEnvironment created\n",
      "Namespace(dump_path='./dumped/', exp_name='first_train', save_periodic=0, exp_id='dmytro_job', fp16=False, amp=-1, emb_dim=64, bottleneck_dim=64, nn_output=1, input_seq_length=47, n_enc_layers=16, n_dec_layers=4, n_heads=4, dropout=0.1, attention_dropout=0.1, share_inout_emb=False, sinusoidal_embeddings=True, env_base_seed=0, max_len=512, batch_size=32, optimizer='adam,lr=0.0001', clip_grad_norm=5, epoch_size=10000, max_epoch=100000, stopping_criterion='', validation_metrics='', accumulate_gradients=1, num_workers=4, same_nb_ops_per_batch=False, reload_size=-1, env_name='sai', tasks='add_dataset', beam_eval=False, beam_size=1, beam_length_penalty=1, beam_early_stopping=True, reload_model='', reload_checkpoint='', eval_only=False, eval_verbose=0, eval_verbose_print=False, debug_slurm=False, debug=False, cpu=False, local_rank=-1, master_port=-1)\n",
      "SLURM job: False\n",
      "0 - Number of nodes: 1\n",
      "0 - Node ID        : 0\n",
      "0 - Local rank     : 0\n",
      "0 - Global rank    : 0\n",
      "0 - World size     : 1\n",
      "0 - GPUs per node  : 1\n",
      "0 - Master         : True\n",
      "0 - Multi-node     : False\n",
      "0 - Multi-GPU      : False\n",
      "0 - Hostname       : DESKTOP-GPBACS8\n",
      "gpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 01/05/23 22:48:20 - 0:00:00 - Number of parameters (transformer): 1598630\n",
      "INFO - 01/05/23 22:48:20 - 0:00:00 - Found 370 parameters in model.\n",
      "INFO - 01/05/23 22:48:21 - 0:00:01 - Optimizers: model\n",
      "INFO - 01/05/23 22:48:21 - 0:00:01 - Number of parameters (transformer): 1598630\n",
      "INFO - 01/05/23 22:48:21 - 0:00:02 - Found 370 parameters in model.\n",
      "INFO - 01/05/23 22:48:23 - 0:00:03 - Optimizers: model\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import string\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import src\n",
    "from envs import build_env\n",
    "#from src.evaluator import Evaluator\n",
    "from src.slurm import init_signal_handler, init_distributed_mode\n",
    "from t2.realtime_trainer import RealtimeTrainer\n",
    "from src.utils import initialize_exp\n",
    "from t2.utils import get_parser\n",
    "\n",
    "from t2.transformer import build_transformer\n",
    "argv = [\n",
    "        '--exp_name', 'first_train', \n",
    "        '--tasks', 'add_dataset', \n",
    "        '--n_enc_layers', '16', \n",
    "        '--n_heads', '4', \n",
    "        '--sinusoidal_embeddings', 'true', \n",
    "        '--num_workers', '4', \n",
    "        '--eval_onl', '0', \n",
    "        '--save_periodic', '0', \n",
    "        '--epoch_size', '10000', \n",
    "        '--batch_size', '32', \n",
    "        '--dropout', '0.1', \n",
    "        '--attention_dropout', '0.1', \n",
    "        '--emb_dim', '64', \n",
    "        '--bottleneck_dim', '64', \n",
    "        '--nn_output', '1', \n",
    "        '--input_seq_length', '47', \n",
    "        '--share_inout_emb', 'false'\n",
    "]\n",
    "\n",
    "parser = get_parser()\n",
    "\n",
    "params = parser.parse_args(argv)\n",
    "#params.input_seq_length = len(\"ABABAGALAMAGAABABAGALAMAGAABABAGALAMAGAABABAG\") + 2\n",
    "print(params)\n",
    "\n",
    "bs = params.batch_size\n",
    "#dim = params.emb_dim\n",
    "\n",
    "init_distributed_mode(params)\n",
    "logger = initialize_exp(params)\n",
    "\n",
    "# CPU / CUDA\n",
    "if params.cpu:\n",
    "    assert not params.multi_gpu\n",
    "else:\n",
    "    assert torch.cuda.is_available()\n",
    "    print(\"gpu\")\n",
    "    \n",
    "src.utils.CUDA = not params.cpu\n",
    "\n",
    "env = build_env(params)\n",
    "\n",
    "# modules = build_transformer(env, params, 'cuda')\n",
    "# trainer = RealtimeTrainer(modules, env, params)\n",
    "\n",
    "trainers=[]\n",
    "number_of_models=2\n",
    "# for i in range(number_of_models):\n",
    "#     modules = build_transformer(env, params, 'cuda')\n",
    "\n",
    "#     trainer = RealtimeTrainer(modules, env, params)\n",
    "    \n",
    "#     trainers += [trainer]\n",
    "\n",
    "params.my_device='cuda:0'\n",
    "trainer = RealtimeTrainer(build_transformer(env, params), env, params)\n",
    "trainers += [trainer]\n",
    "\n",
    "params.my_device='cuda:1'\n",
    "\n",
    "trainer = RealtimeTrainer(build_transformer(env, params), env, params)\n",
    "trainers += [trainer]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act(inp, trainer):\n",
    "    inp = join_sai(inp)\n",
    "    lst = []\n",
    "    for _ in range(bs):\n",
    "        x = inp\n",
    "        lst += [x]\n",
    "        \n",
    "    return trainer.act(lst)[0]\n",
    "\n",
    "def to_sai_str(p):\n",
    "    return join_sai(p.data)\n",
    "\n",
    "\n",
    "def join_sai(data):\n",
    "    return ' '.join(data)\n",
    "\n",
    "def str_diff(s1, s2):\n",
    "    diff = abs(len(s1) - len(s2))\n",
    "    for i in range(min(len(s1), len(s2))):\n",
    "        diff += 1 if s1[i] != s2[i] else 0\n",
    "    return diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 'KAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAE'\n",
    "a = join_sai(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\workspace\\ai\\Transformers1\\src\\optim.py:72: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\python_arg_parser.cpp:1418.)\n",
      "  exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
      "INFO - 01/05/23 22:48:24 - 0:00:04 - learning: av-score=0.7273936170212765, device=cuda:0\n",
      "INFO - 01/05/23 22:48:24 - 0:00:05 - learning: av-score=0.04188829787234042, device=cuda:1\n",
      "INFO - 01/05/23 22:48:25 - 0:00:05 - learning: av-score=0.7938829787234043, device=cuda:0\n",
      "INFO - 01/05/23 22:48:25 - 0:00:05 - learning: av-score=0.35172872340425543, device=cuda:1\n",
      "INFO - 01/05/23 22:48:25 - 0:00:05 - learning: av-score=0.5378989361702127, device=cuda:0\n",
      "INFO - 01/05/23 22:48:25 - 0:00:05 - learning: av-score=0.774601063829787, device=cuda:1\n",
      "INFO - 01/05/23 22:48:25 - 0:00:06 - learning: av-score=0.5797872340425531, device=cuda:0\n",
      "INFO - 01/05/23 22:48:26 - 0:00:06 - learning: av-score=0.8916223404255319, device=cuda:1\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "losses = []\n",
    "iterations_number = 10\n",
    "\n",
    "for it in range(iterations_number):\n",
    "    for trainer in trainers:\n",
    "            for _ in range(params.batch_size):\n",
    "                loss = trainer.learn(a, a)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "av_time = elapsed_time/iterations_number/len(trainers)\n",
    "\n",
    "print(f'Av time per iteration per trainer: {elapsed_time/iterations_number:.2f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(trainers[0].modules['transformer'].te1.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 'KAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAE'\n",
    "B = 'KBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBE'\n",
    "X = 'KAAADAAAAADAAAAAMAAAAAAAAAAASAAAALAAAAAFNAAZE'\n",
    "\n",
    "#rnds = [gen_rnd_chars(xy_data_size_const) for _ in range(100)]\n",
    "\n",
    "print(trainers[0].act(A))\n",
    "print(trainers[0].act(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A = 'KAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAE'\n",
    "B = 'KBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBE'\n",
    "X = 'KAAADAAAAADAAAAAMAAAAAAAAAAASAAAALAAAAAFNAAZE'\n",
    "\n",
    "losses = []\n",
    "for it in range(2000):\n",
    "    loss = trainer.learn(join_sai(A), join_sai(A))\n",
    "    if loss[0]:\n",
    "        l = loss[1].item()\n",
    "        losses += [l]\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.title('los s vs iteration')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(act(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(act(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}