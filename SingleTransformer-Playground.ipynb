{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 01/08/23 18:24:07 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 01/08/23 18:24:07 - 0:00:00 - accumulate_gradients: 1\n",
      "                                     amp: -1\n",
      "                                     attention_dropout: 0.1\n",
      "                                     batch_size: 32\n",
      "                                     beam_early_stopping: True\n",
      "                                     beam_eval: False\n",
      "                                     beam_length_penalty: 1\n",
      "                                     beam_size: 1\n",
      "                                     bottleneck_dim: 64\n",
      "                                     clip_grad_norm: 5\n",
      "                                     command: python F:\\Programs\\anaconda3\\envs\\ai\\lib\\site-packages\\ipykernel_launcher.py '-f' 'C:\\Users\\Dmytro\\AppData\\Roaming\\jupyter\\runtime\\kernel-657dd551-23fc-4593-8171-0748d559e9dc.json' --exp_id \"dmytro_job\"\n",
      "                                     cpu: False\n",
      "                                     debug: False\n",
      "                                     debug_slurm: False\n",
      "                                     dropout: 0.1\n",
      "                                     dump_path: ./dumped/\n",
      "                                     emb_dim: 64\n",
      "                                     env_base_seed: 0\n",
      "                                     env_name: sai\n",
      "                                     epoch_size: 10000\n",
      "                                     eval_only: False\n",
      "                                     eval_verbose: 0\n",
      "                                     eval_verbose_print: False\n",
      "                                     exp_id: dmytro_job\n",
      "                                     exp_name: first_train\n",
      "                                     fp16: False\n",
      "                                     global_rank: 0\n",
      "                                     input_seq_length: 47\n",
      "                                     is_master: True\n",
      "                                     is_slurm_job: False\n",
      "                                     local_rank: 0\n",
      "                                     master_port: -1\n",
      "                                     max_epoch: 100000\n",
      "                                     max_len: 512\n",
      "                                     multi_gpu: False\n",
      "                                     multi_node: False\n",
      "                                     my_device: cuda\n",
      "                                     n_dec_layers: 4\n",
      "                                     n_enc_layers: 16\n",
      "                                     n_gpu_per_node: 1\n",
      "                                     n_heads: 4\n",
      "                                     n_nodes: 1\n",
      "                                     nn_output: 1\n",
      "                                     node_id: 0\n",
      "                                     num_workers: 4\n",
      "                                     optimizer: adam,lr=0.0001\n",
      "                                     reload_checkpoint: \n",
      "                                     reload_model: \n",
      "                                     reload_size: -1\n",
      "                                     same_nb_ops_per_batch: False\n",
      "                                     save_periodic: 0\n",
      "                                     share_inout_emb: False\n",
      "                                     sinusoidal_embeddings: True\n",
      "                                     stopping_criterion: \n",
      "                                     tasks: add_dataset\n",
      "                                     validation_metrics: \n",
      "                                     world_size: 1\n",
      "INFO - 01/08/23 18:24:07 - 0:00:00 - The experiment will be stored in ./dumped/\n",
      "                                     \n",
      "INFO - 01/08/23 18:24:07 - 0:00:00 - Running command: python F:\\Programs\\anaconda3\\envs\\ai\\lib\\site-packages\\ipykernel_launcher.py '-f' 'C:\\Users\\Dmytro\\AppData\\Roaming\\jupyter\\runtime\\kernel-657dd551-23fc-4593-8171-0748d559e9dc.json'\n",
      "\n",
      "INFO - 01/08/23 18:24:07 - 0:00:00 - words: {'<s>': 0, '</s>': 1, 'A': 2, 'B': 3, 'C': 4, 'D': 5, 'E': 6, 'F': 7, 'G': 8, 'H': 9, 'I': 10, 'J': 11, 'K': 12, 'L': 13, 'M': 14, 'N': 15, 'O': 16, 'P': 17, 'Q': 18, 'R': 19, 'S': 20, 'T': 21, 'U': 22, 'V': 23, 'W': 24, 'X': 25, 'Y': 26, 'Z': 27, '0': 28, '1': 29, '2': 30, '3': 31, '4': 32, '5': 33, '6': 34, '7': 35, '8': 36, '9': 37}\n",
      "INFO - 01/08/23 18:24:07 - 0:00:00 - Training tasks: add_dataset\n",
      "INFO - 01/08/23 18:24:07 - 0:00:00 - Number of parameters (transformer): 1598630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAIEnvironment created\n",
      "Namespace(dump_path='./dumped/', exp_name='first_train', save_periodic=0, exp_id='dmytro_job', fp16=False, amp=-1, emb_dim=64, bottleneck_dim=64, nn_output=1, input_seq_length=47, n_enc_layers=16, n_dec_layers=4, n_heads=4, dropout=0.1, attention_dropout=0.1, share_inout_emb=False, sinusoidal_embeddings=True, env_base_seed=0, max_len=512, batch_size=32, optimizer='adam,lr=0.0001', clip_grad_norm=5, epoch_size=10000, max_epoch=100000, stopping_criterion='', validation_metrics='', accumulate_gradients=1, num_workers=4, same_nb_ops_per_batch=False, reload_size=-1, env_name='sai', tasks='add_dataset', beam_eval=False, beam_size=1, beam_length_penalty=1, beam_early_stopping=True, reload_model='', reload_checkpoint='', eval_only=False, eval_verbose=0, eval_verbose_print=False, debug_slurm=False, debug=False, cpu=False, local_rank=-1, master_port=-1, my_device='cuda')\n",
      "SLURM job: False\n",
      "0 - Number of nodes: 1\n",
      "0 - Node ID        : 0\n",
      "0 - Local rank     : 0\n",
      "0 - Global rank    : 0\n",
      "0 - World size     : 1\n",
      "0 - GPUs per node  : 1\n",
      "0 - Master         : True\n",
      "0 - Multi-node     : False\n",
      "0 - Multi-GPU      : False\n",
      "0 - Hostname       : DESKTOP-GPBACS8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 01/08/23 18:24:07 - 0:00:00 - Found 370 parameters in model.\n",
      "INFO - 01/08/23 18:24:08 - 0:00:01 - Optimizers: model\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import src\n",
    "from envs import build_env\n",
    "#from src.evaluator import Evaluator\n",
    "from src.slurm import init_signal_handler, init_distributed_mode\n",
    "from t2.realtime_trainer import RealtimeTrainer\n",
    "from src.utils import initialize_exp, str_diff\n",
    "from t2.utils import get_parser, join_sai, to_sai_str\n",
    "\n",
    "from t2.transformer import build_transformer\n",
    "argv = [\n",
    "        '--exp_name', 'first_train', \n",
    "        '--tasks', 'add_dataset', \n",
    "        '--n_enc_layers', '16', \n",
    "        '--n_heads', '4', \n",
    "        '--sinusoidal_embeddings', 'true', \n",
    "        '--num_workers', '4', \n",
    "        '--eval_onl', '0', \n",
    "        '--save_periodic', '0', \n",
    "        '--epoch_size', '10000', \n",
    "        '--batch_size', '32', \n",
    "        '--dropout', '0.1', \n",
    "        '--attention_dropout', '0.1', \n",
    "        '--emb_dim', '64', \n",
    "        '--bottleneck_dim', '64', \n",
    "        '--nn_output', '1', \n",
    "        '--input_seq_length', '47', \n",
    "        '--share_inout_emb', 'false'\n",
    "]\n",
    "\n",
    "parser = get_parser()\n",
    "\n",
    "params = parser.parse_args(argv)\n",
    "params.my_device='cuda'\n",
    "\n",
    "print(params)\n",
    "\n",
    "bs = params.batch_size\n",
    "#dim = params.emb_dim\n",
    "\n",
    "init_distributed_mode(params)\n",
    "logger = initialize_exp(params)\n",
    "\n",
    "# CPU / CUDA\n",
    "if params.cpu:\n",
    "    assert not params.multi_gpu\n",
    "else:\n",
    "    assert torch.cuda.is_available()\n",
    "    \n",
    "src.utils.CUDA = not params.cpu\n",
    "\n",
    "env = build_env(params)\n",
    "\n",
    "modules = build_transformer(env, params)\n",
    "trainer = RealtimeTrainer(modules, env, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37, 37, 37, 37, 35, 37, 37, 37, 11, 37, 37, 37, 37, 33, 26, 37, 37, 37, 33, 13, 3, 2, 13, 9, 26, 33, 13, 33, 37, 26, 33, 35, 5, 35, 2, 33, 35, 26, 5, 26, 26, 33, 33, 34, 6, 33, 37, 35, 33, 37, 5, 13, 33, 35, 35, 33, 26, 2, 37, 37, 37, 37, 26, 35, 3, 37, 35, 4, 33, 1, 37, 35, 33, 33, 26, 33, 2, 4, 29, 35, 33, 33, 35, 35, 1, 33, 33, 33, 35, 13, 35, 37, 33, 33, 26, 33, 35, 33, 35, 2, 34, 33, 37, 33, 33, 33, 33, 26, 11, 26, 33, 37, 5, 35, 33, 6, 2, 37, 35, 37, 35, 37, 33, 35, 37, 37, 33, 4, 33, 8, 2, 37, 33, 8, 33]\n"
     ]
    }
   ],
   "source": [
    "A = 'KAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEKAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEKAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAE'\n",
    "\n",
    "print(trainer.single_act_detailed(A,A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 a\n",
      "   \n",
      "2 b\n",
      "   \n",
      "3 c\n"
     ]
    }
   ],
   "source": [
    "c = join_sai('123')\n",
    "b = join_sai('abc')\n",
    "\n",
    "for l,m in zip(c,b):\n",
    "    print(l,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7796/3499522655.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterations_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrainers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainers' is not defined"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "losses = []\n",
    "iterations_number = 10\n",
    "\n",
    "for it in range(iterations_number):\n",
    "    for trainer in trainers:\n",
    "            for _ in range(params.batch_size):\n",
    "                loss = trainer.learn(a, a)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "av_time = elapsed_time/iterations_number/len(trainers)\n",
    "\n",
    "print(f'Av time per iteration per trainer: {elapsed_time/iterations_number:.2f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name(next(trainers[0].modules['transformer'].te1.parameters()).device.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A = 'KAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAE'\n",
    "B = 'KBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBE'\n",
    "X = 'KAAADAAAAADAAAAAMAAAAAAAAAAASAAAALAAAAAFNAAZE'\n",
    "\n",
    "#rnds = [gen_rnd_chars(xy_data_size_const) for _ in range(100)]\n",
    "\n",
    "print(trainers[0].act(A))\n",
    "print(trainers[0].act(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A = 'KAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAE'\n",
    "B = 'KBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBE'\n",
    "X = 'KAAADAAAAADAAAAAMAAAAAAAAAAASAAAALAAAAAFNAAZE'\n",
    "\n",
    "losses = []\n",
    "for it in range(2000):\n",
    "    loss = trainer.learn(join_sai(A), join_sai(A))\n",
    "    if loss[0]:\n",
    "        l = loss[1].item()\n",
    "        losses += [l]\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.title('los s vs iteration')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(act(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(act(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mp.set_start_method('spawn', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def m():\n",
    "    while True:\n",
    "        print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p = mp.Process(target=m, args=())\n",
    "\n",
    "p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
