{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3824b661-3154-45af-8b8f-bce8c7043a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/share/input.txt', '/share/us-stock-dataset', '/share/Transformers1']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "print(glob.glob(\"/share/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa155bcd-db9c-4f57-9ad6-f91ed1f1823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "import glob\n",
    "\n",
    "from t4.timeseries_transformer import TransformerConfig, TransformerRunner\n",
    "\n",
    "from timeseries.csv_reader import read_and_merge_csv_files\n",
    "\n",
    "from t3_karpathy.commons.commons import BaseTransformerConfig\n",
    "from t3_karpathy.token_codec import TokenCodec\n",
    "from t4.generic_dataloader import GenericDataloader\n",
    "from timeseries.timeseries_transformer import TimeseriesDataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1e8389d-be54-46eb-97da-8cfb245928bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and merging CSV files: ['AAPL', 'TSLA', 'A', 'GOOG', 'AMZN', 'PYPL', 'NVDA', 'AMD', 'NFLX', 'MSFT', 'INTC', 'CSCO', 'ADBE', 'CRM', 'QCOM', 'TXN', 'AVGO', 'INTU', 'ORCL', 'COST', 'SBUX', 'AMGN', 'CHTR', 'GILD', 'CMCSA', 'BKNG', 'MDLZ', 'FISV', 'BIIB', 'MU', 'MCD', 'AMAT', 'ADP', 'ILMN', 'ATVI', 'ISRG', 'ADSK', 'LRCX', 'BIDU', 'JD', 'REGN', 'WBA', 'VRTX', 'KHC', 'WMT', 'ZM', 'MELI', 'TMUS', 'CTSH', 'XLNX', 'PCAR', 'ALGN', 'WDAY', 'SIRI', 'CTXS', 'ADI', 'EXC', 'LULU', 'MAR', 'KLAC', 'PAYX', 'EA', 'ILMN', 'ALXN', 'MNST', 'BMRN', 'EBAY', 'CTAS', 'VRSK', 'IDXX', 'CDNS', 'NXPI', 'ASML', 'INCY', 'KLAC', 'MCHP', 'SNPS', 'SWKS', 'VRSN', 'WDC', 'WYNN', 'XLNX', 'ZBRA', 'ZTS', 'AEP', 'AIG', 'ALL', 'AXP', 'BA', 'BAC', 'BK', 'BLK', 'C', 'CAT', 'CL', 'COF', 'COP', 'COST', 'CSCO', 'CVS', 'CVX', 'DD', 'DHR', 'DIS', 'DOW', 'DUK', 'EMR', 'EXC', 'F', 'FDX', 'GD', 'GE', 'GILD', 'GM', 'GOOG', 'GOOGL', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'JPM', 'KHC', 'KMI', 'KO', 'LLY', 'LMT', 'LOW', 'MA', 'MCD', 'MDLZ', 'MDT', 'MET', 'MMM', 'BLND', 'BLNG', 'BLNKW', 'BLNGU', 'BLNGW', 'BLNK', 'BLPH', 'BLRX', 'BLTE', 'BLU', 'BLUA', 'BLUE', 'BLW', 'BLX', 'BLZE', 'BMA', 'BMAC', 'BMAQ', 'BMAQR', 'BMAQU']\n",
      "File /share/us-stock-dataset/Data/Stocks/XLNX.csv not found\n",
      "File /share/us-stock-dataset/Data/Stocks/CTXS.csv not found\n",
      "File /share/us-stock-dataset/Data/Stocks/ALXN.csv not found\n",
      "File /share/us-stock-dataset/Data/Stocks/XLNX.csv not found\n",
      "File /share/us-stock-dataset/Data/Stocks/BLNKW.csv not found\n",
      "File /share/us-stock-dataset/Data/Stocks/BLNGU.csv not found\n",
      "File /share/us-stock-dataset/Data/Stocks/BLNGW.csv not found\n",
      "File /share/us-stock-dataset/Data/Stocks/BMAQ.csv not found\n",
      "File /share/us-stock-dataset/Data/Stocks/BMAQR.csv not found\n",
      "File /share/us-stock-dataset/Data/Stocks/BMAQU.csv not found\n",
      "Found files:  145\n",
      "torch.Size([5283, 145])\n"
     ]
    }
   ],
   "source": [
    "stocks_to_load = [\n",
    "    \"AAPL\", \"TSLA\",\n",
    "    \"A\", \"GOOG\", \"AMZN\", \"PYPL\", \"NVDA\", \"AMD\",\n",
    "    \"NFLX\", \"MSFT\", \"INTC\", \"CSCO\", \"ADBE\", \"CRM\", \"QCOM\", \"TXN\", \"AVGO\",\n",
    "    \"INTU\", \"ORCL\", \"COST\", \"SBUX\", \"AMGN\", \"CHTR\", \"GILD\", \"CMCSA\", \"BKNG\",\n",
    "    \"MDLZ\", \"FISV\", \"BIIB\", \"MU\", \"MCD\", \"AMAT\", \"ADP\", \"ILMN\", \"ATVI\", \"ISRG\",\n",
    "    \"ADSK\", \"LRCX\", \"BIDU\", \"JD\", \"REGN\", \"WBA\", \"VRTX\", \"KHC\", \"WMT\", \"ZM\", \"MELI\",\n",
    "    \"TMUS\", \"CTSH\", \"XLNX\", \"PCAR\", \"ALGN\", \"WDAY\", \"SIRI\", \"CTXS\", \"ADI\", \"EXC\", \"LULU\",\n",
    "    \"MAR\", \"KLAC\", \"PAYX\", \"EA\", \"ILMN\", \"ALXN\", \"MNST\", \"BMRN\", \"EBAY\", \"CTAS\", \"VRSK\",\n",
    "    \"IDXX\", \"CDNS\", \"NXPI\", \"ASML\", \"INCY\", \"KLAC\", \"MCHP\", \"SNPS\", \"SWKS\", \"VRSN\",\n",
    "    \"WDC\", \"WYNN\", \"XLNX\", \"ZBRA\", \"ZTS\", \"AEP\", \"AIG\", \"ALL\", \"AXP\", \"BA\", \"BAC\",\n",
    "    \"BK\", \"BLK\", \"C\", \"CAT\", \"CL\", \"COF\", \"COP\", \"COST\", \"CSCO\", \"CVS\", \"CVX\",\n",
    "    \"DD\", \"DHR\", \"DIS\", \"DOW\", \"DUK\", \"EMR\", \"EXC\", \"F\", \"FDX\", \"GD\", \"GE\", \"GILD\",\n",
    "    \"GM\", \"GOOG\", \"GOOGL\", \"GS\", \"HD\", \"HON\", \"IBM\", \"INTC\", \"JNJ\", \"JPM\", \"KHC\", \"KMI\",\n",
    "    \"KO\", \"LLY\", \"LMT\", \"LOW\", \"MA\", \"MCD\", \"MDLZ\", \"MDT\", \"MET\", \"MMM\",\n",
    "    'BLND', 'BLNG', 'BLNKW', 'BLNGU', 'BLNGW', 'BLNK', 'BLPH', 'BLRX',\n",
    "    'BLTE', 'BLU', 'BLUA', 'BLUE', 'BLW', 'BLX', 'BLZE', 'BMA', 'BMAC', 'BMAQ', 'BMAQR', 'BMAQU'\n",
    "]\n",
    "\n",
    "directory_path = '/share/us-stock-dataset/Data/Stocks'\n",
    "\n",
    "# stocks_to_load = [s.split(\"\\\\\")[1].replace(\".csv\", \"\") for s in glob.glob(directory_path + \"//*.csv\")]\n",
    "#\n",
    "# stock_number_to_load = 200\n",
    "#\n",
    "# stocks_to_load = stocks_to_load[1000:1000+stock_number_to_load]\n",
    "\n",
    "dataloader = TimeseriesDataloader(directory_path, stocks_to_load, add_diff=False)\n",
    "\n",
    "print(dataloader.get_data().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b3d0f72-a816-4330-9ce9-b23c73f874b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.4947e-01, 1.5927e+00, 4.3930e+01, 2.4991e+00, 4.4688e+00, 3.6710e+01,\n",
       "        8.9489e-01, 1.5500e+01, 1.1964e+00, 3.6282e+01, 2.5214e+01, 3.7781e+01,\n",
       "        1.6275e+01, 4.3000e+00, 5.9089e+01, 3.4013e+01, 1.1836e+01, 2.7018e+01,\n",
       "        2.4375e+01, 3.0857e+01, 2.4508e+00, 4.6329e+01, 3.5000e+01, 1.3459e+00,\n",
       "        1.1592e+01, 3.0750e+02, 1.2123e+01, 6.3542e+00, 3.1083e+01, 3.7509e+01,\n",
       "        2.2424e+01, 2.3480e+01, 2.5348e+01, 1.9586e+01, 1.2144e+00, 2.0278e+00,\n",
       "        8.0529e+00, 3.2735e+01, 1.2254e+01, 2.0084e+01, 1.2312e+01, 1.8248e+01,\n",
       "        1.8781e+01, 5.2814e+01, 4.3873e+01, 6.2000e+01, 2.7616e+01, 4.5404e+01,\n",
       "        1.8462e+00, 2.6263e+00, 1.6875e+01, 4.8690e+01, 3.6274e+01, 2.8982e+01,\n",
       "        5.1753e+00, 1.4000e+01, 1.1493e+01, 2.9200e+01, 1.3783e+01, 2.4923e+01,\n",
       "        1.9586e+01, 4.4922e-02, 1.2750e+01, 6.9658e+00, 2.6095e+01, 2.6463e+01,\n",
       "        4.0156e+00, 2.2062e+01, 1.3085e+01, 2.7219e+01, 4.4828e+01, 2.9200e+01,\n",
       "        5.8364e+00, 3.2781e+01, 2.7434e+01, 1.6144e+02, 3.1610e+00, 7.1631e+00,\n",
       "        2.5028e+01, 2.8823e+01, 1.1245e+01, 8.6711e+02, 1.3349e+01, 3.3313e+01,\n",
       "        2.5940e+01, 1.3357e+01, 2.3116e+01, 1.0618e+01, 2.2696e+02, 1.3100e+01,\n",
       "        1.8852e+01, 3.4805e+01, 8.2113e+00, 3.0857e+01, 3.7781e+01, 1.3315e+01,\n",
       "        1.7677e+01, 2.9800e+01, 8.2283e+00, 2.3115e+01, 4.0303e+01, 1.4276e+01,\n",
       "        1.4877e+01, 5.1753e+00, 1.3551e+01, 3.6468e+01, 1.5102e+01, 1.6477e+02,\n",
       "        1.3459e+00, 2.6245e+01, 2.4991e+00, 2.5110e+00, 6.5691e+01, 4.0630e+01,\n",
       "        3.1825e+01, 6.2428e+01, 2.5214e+01, 2.5268e+01, 2.4406e+01, 5.2814e+01,\n",
       "        1.7426e+01, 1.4894e+01, 3.3200e+01, 1.1287e+01, 1.0264e+01, 4.2407e+00,\n",
       "        2.2424e+01, 1.2123e+01, 2.3198e+01, 8.2132e+00, 2.5143e+01, 2.0900e+01,\n",
       "        9.7000e+00, 2.5250e+03, 1.3455e+02, 7.5450e+01, 1.0590e+01, 1.4014e+03,\n",
       "        9.7100e+00, 1.7429e+01, 4.2453e+00, 6.0813e+00, 1.9900e+01, 1.5607e+01,\n",
       "        9.8600e+00], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.get_data()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3cc4a0c-0346-418d-90b0-ae64ffe484b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.201472 M parameters\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m config \u001b[38;5;241m=\u001b[39m TransformerConfig(\u001b[38;5;28;01mNone\u001b[39;00m, precision\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, block_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, n_embed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, n_head\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, n_layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      7\u001b[0m runner \u001b[38;5;241m=\u001b[39m TransformerRunner(config, dataloader\u001b[38;5;241m.\u001b[39mget_data())\n\u001b[0;32m----> 9\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_iterate_n\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# print(dataloader.token_codec.decode(runner.generate(context, max_new_tokens=2000)[0].tolist()))\u001b[39;00m\n",
      "File \u001b[0;32m/share/Transformers1/t3_karpathy/commons/commons.py:115\u001b[0m, in \u001b[0;36mAbstractRunner.train_iterate_n\u001b[0;34m(self, n_iter)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_iterate_n\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_iter):\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_iterate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_train_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_val_batch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/Transformers1/t3_karpathy/commons/commons.py:129\u001b[0m, in \u001b[0;36mAbstractRunner.train_iterate\u001b[0;34m(self, n_iter, get_train_batch, get_val_batch)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_interval \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_iteration \u001b[38;5;241m%\u001b[39m eval_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    128\u001b[0m     t_taken \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t\n\u001b[0;32m--> 129\u001b[0m     train_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_train_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_iters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     val_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(get_val_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39meval_iters)\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_iteration\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: train loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_losses\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_losses\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, time/iter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_taken\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39meval_interval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/Transformers1/t3_karpathy/commons/commons.py:110\u001b[0m, in \u001b[0;36mAbstractRunner.evaluate\u001b[0;34m(self, get_batch, eval_iters)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(eval_iters):\n\u001b[1;32m    109\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m get_batch()\n\u001b[0;32m--> 110\u001b[0m     logits, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_vs_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     losses[k] \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m losses\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m/share/Transformers1/t4/timeseries_transformer.py:81\u001b[0m, in \u001b[0;36mTransformerModel.forward_vs_target\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_vs_target\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx, targets):\n\u001b[0;32m---> 81\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     b, t, c \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     84\u001b[0m     logits_view \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mview(b \u001b[38;5;241m*\u001b[39m t, c)\n",
      "File \u001b[0;32m/share/Transformers1/t4/timeseries_transformer.py:91\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inp):\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/Transformers1/t4/timeseries_transformer.py:62\u001b[0m, in \u001b[0;36mBlockSequence.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m---> 62\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/share/Transformers1/t4/timeseries_transformer.py:50\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 50\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffwd\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln2(x))\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/share/Transformers1/t4/timeseries_transformer.py:31\u001b[0m, in \u001b[0;36mFlashMultiHeadAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 31\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflash_mha\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/flash-attention/flash_attn/modules/mha.py:492\u001b[0m, in \u001b[0;36mMHA.forward\u001b[0;34m(self, x, x_kv, key_padding_mask, cu_seqlens, max_seqlen, mixer_subset, inference_params, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m     qkv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWqkv(x)\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 492\u001b[0m     qkv, x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWqkv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdwconv:\n\u001b[1;32m    494\u001b[0m     qkv \u001b[38;5;241m=\u001b[39m rearrange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdwconv_qkv(rearrange(qkv, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb s d -> b d s\u001b[39m\u001b[38;5;124m'\u001b[39m))[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m    495\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb d s -> b s d\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/flash-attention/flash_attn/modules/mha.py:252\u001b[0m, in \u001b[0;36mLinearResidual.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "config = TransformerConfig(None, precision=torch.bfloat16, batch_size=32, block_size=16, n_embed=64, n_head=4, n_layer=4)\n",
    "\n",
    "runner = TransformerRunner(config, dataloader.get_data())\n",
    "\n",
    "runner.train_iterate_n(2500)\n",
    "\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "# print(dataloader.token_codec.decode(runner.generate(context, max_new_tokens=2000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1e562-234f-4f1b-b9f5-e47593792134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
