{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d440a293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the embedding layer\n",
    "embedding = nn.Embedding(num_embeddings=10, embedding_dim=5)\n",
    "\n",
    "# Create a tensor of indices to look up\n",
    "x = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 0])\n",
    "\n",
    "# Look up the embeddings for the indices\n",
    "embeddings = embedding(x)\n",
    "\n",
    "print(embeddings.shape)  # Output: torch.Size([10, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecdc072b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1280, -1.3899,  0.1328,  0.6708, -0.1988],\n",
       "        [ 1.5122, -0.5040, -0.6624, -0.4553,  0.8822],\n",
       "        [ 0.3563, -2.0542,  0.3366, -1.3629,  0.3277],\n",
       "        [-1.4544,  2.0814, -0.6531,  0.6651, -1.1274],\n",
       "        [-0.0235,  0.0755, -0.4740,  0.1013, -0.4427],\n",
       "        [ 0.5397,  0.7927, -0.2936,  0.1826,  0.8001],\n",
       "        [ 0.4999,  1.7437, -1.0513,  0.0411, -0.5273],\n",
       "        [ 1.5823,  0.0980, -1.2403,  0.0772, -0.3177],\n",
       "        [ 1.3072, -0.9687, -0.5078,  1.6846, -1.1209],\n",
       "        [-0.0133,  0.1113, -0.7030,  0.3981,  0.4362]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4551f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the embedding layer\n",
    "embedding = nn.Embedding(num_embeddings=10, embedding_dim=5)\n",
    "\n",
    "# Create a tensor of word embeddings\n",
    "word_embeddings = embedding(x)\n",
    "\n",
    "# Create a tensor of position indices\n",
    "positions = torch.arange(len(x)).unsqueeze(1)\n",
    "\n",
    "# Create a tensor of sinusoidal position embeddings\n",
    "sinusoidal_pos_embeddings = torch.sin(positions / 10000 ** (torch.arange(5, dtype=torch.float) / 5))\n",
    "\n",
    "# Concatenate the word embeddings and the position embeddings\n",
    "embeddings = torch.cat([word_embeddings, sinusoidal_pos_embeddings], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4c51e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa96426c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2388e+00,  4.3046e-01,  7.9002e-01,  1.8007e-01,  2.2428e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 6.3579e-01, -6.1091e-01,  2.2454e-01, -2.6604e-01,  8.5151e-01,\n",
       "          8.4147e-01,  1.5783e-01,  2.5116e-02,  3.9811e-03,  6.3096e-04],\n",
       "        [ 2.4731e-01, -7.8893e-01,  1.9988e-01, -2.8187e-01, -8.9224e-01,\n",
       "          9.0930e-01,  3.1170e-01,  5.0217e-02,  7.9621e-03,  1.2619e-03],\n",
       "        [ 1.1950e+00,  1.2299e+00,  5.5570e-01, -5.1588e-01,  6.6199e-01,\n",
       "          1.4112e-01,  4.5775e-01,  7.5285e-02,  1.1943e-02,  1.8929e-03],\n",
       "        [ 1.8623e+00,  2.1693e-01,  1.8577e+00, -1.9445e-01,  8.0941e-01,\n",
       "         -7.5680e-01,  5.9234e-01,  1.0031e-01,  1.5924e-02,  2.5238e-03],\n",
       "        [ 1.6415e+00,  1.0613e+00,  1.2379e-01, -3.8771e-01, -8.0770e-01,\n",
       "         -9.5892e-01,  7.1207e-01,  1.2526e-01,  1.9904e-02,  3.1548e-03],\n",
       "        [ 4.4007e-01, -9.3920e-01,  1.3637e+00,  1.5609e+00, -1.5175e+00,\n",
       "         -2.7942e-01,  8.1396e-01,  1.5014e-01,  2.3884e-02,  3.7857e-03],\n",
       "        [ 7.0247e-01,  3.6657e-01,  4.0491e-01, -8.0207e-01,  2.4639e-01,\n",
       "          6.5699e-01,  8.9544e-01,  1.7493e-01,  2.7864e-02,  4.4167e-03],\n",
       "        [ 9.3961e-01,  8.6924e-01,  2.6387e-01, -6.6879e-01, -8.6009e-01,\n",
       "          9.8936e-01,  9.5448e-01,  1.9960e-01,  3.1843e-02,  5.0476e-03],\n",
       "        [-8.9954e-01,  4.9785e-02, -2.7375e-01,  4.1636e-01, -1.5187e+00,\n",
       "          4.1212e-01,  9.8959e-01,  2.2415e-01,  3.5822e-02,  5.6786e-03]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0b0cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
