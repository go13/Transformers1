{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5827900a-6328-4178-ac86-291d2b8e2f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/share/us-stock-dataset', '/share/Transformers1']\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "print(glob.glob(\"/share/*\"))\n",
    "\n",
    "from torch import nn as nn\n",
    "import torch\n",
    "import faiss\n",
    "from torch_cluster import knn_graph\n",
    "from timeseries.timeseries_transformer import TimeseriesDataloader, TimeseriesTransformerConfig, DistancePositionalEmbedding, PositionalEmbedding,TimeseriesPandasTrainer\n",
    "from t3_karpathy.commons.feed_forwards import GeluFeedForward\n",
    "from t3_karpathy.enhanced_karpathy_transformer import BlockSequence\n",
    "\n",
    "from t3_karpathy.commons.commons import AbstractCodec, AbstractAccumulativeTrainer, AbstractRunner, \\\n",
    "    BaseTransformerConfig, TimeseriesFeedForward\n",
    "\n",
    "from torch_cluster import knn\n",
    "print(torch.cuda.is_available())\n",
    "directory_path = '/share/us-stock-dataset/Data/Stocks'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe2f7a19-86d1-4d73-a18b-e81c50bc22e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stocks_to_load = [\n",
    "    \"AAPL\", \"TSLA\",\n",
    "    \"A\", \"GOOG\", \"AMZN\", \"PYPL\", \"NVDA\", \"AMD\",\n",
    "    \"NFLX\", \"MSFT\", \"INTC\", \"CSCO\", \"ADBE\", \"CRM\", \"QCOM\", \"TXN\", \"AVGO\",\n",
    "    \"INTU\", \"ORCL\", \"COST\", \"SBUX\", \"AMGN\", \"CHTR\", \"GILD\", \"CMCSA\", \"BKNG\",\n",
    "    \"MDLZ\", \"FISV\", \"BIIB\", \"MU\", \"MCD\", \"AMAT\", \"ADP\", \"ILMN\", \"ATVI\", \"ISRG\",\n",
    "    \"ADSK\", \"LRCX\", \"BIDU\", \"JD\", \"REGN\", \"WBA\", \"VRTX\", \"KHC\", \"WMT\", \"ZM\", \"MELI\",\n",
    "    \"TMUS\", \"CTSH\", \"XLNX\", \"PCAR\", \"ALGN\", \"WDAY\", \"SIRI\", \"CTXS\", \"ADI\", \"EXC\", \"LULU\",\n",
    "    \"MAR\", \"KLAC\", \"PAYX\", \"EA\", \"ILMN\", \"ALXN\", \"MNST\", \"BMRN\", \"EBAY\", \"CTAS\", \"VRSK\",\n",
    "    \"IDXX\", \"CDNS\", \"NXPI\", \"ASML\", \"INCY\", \"KLAC\", \"MCHP\", \"SNPS\", \"SWKS\", \"VRSN\",\n",
    "    \"WDC\", \"WYNN\", \"XLNX\", \"ZBRA\", \"ZTS\", \"AEP\", \"AIG\", \"ALL\", \"AXP\", \"BA\", \"BAC\",\n",
    "    \"BK\", \"BLK\", \"C\", \"CAT\", \"CL\", \"COF\", \"COP\", \"COST\", \"CSCO\", \"CVS\", \"CVX\",\n",
    "    \"DD\", \"DHR\", \"DIS\", \"DOW\", \"DUK\", \"EMR\", \"EXC\", \"F\", \"FDX\", \"GD\", \"GE\", \"GILD\",\n",
    "    \"GM\", \"GOOG\", \"GOOGL\", \"GS\", \"HD\", \"HON\", \"IBM\", \"INTC\", \"JNJ\", \"JPM\", \"KHC\", \"KMI\",\n",
    "    \"KO\", \"LLY\", \"LMT\", \"LOW\", \"MA\", \"MCD\", \"MDLZ\", \"MDT\", \"MET\", \"MMM\",\n",
    "    'BLND', 'BLNG', 'BLNKW', 'BLNGU', 'BLNGW', 'BLNK', 'BLPH', 'BLRX',\n",
    "    'BLTE', 'BLU', 'BLUA', 'BLUE', 'BLW', 'BLX', 'BLZE', 'BMA', 'BMAC', 'BMAQ', 'BMAQR', 'BMAQU'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e675dee-013d-4c0c-bca5-636b96e6b599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and merging CSV files: ['AAPL', 'TSLA', 'A', 'GOOG', 'AMZN', 'PYPL', 'NVDA', 'AMD', 'NFLX', 'MSFT', 'INTC', 'CSCO', 'ADBE', 'CRM', 'QCOM', 'TXN', 'AVGO', 'INTU', 'ORCL', 'COST', 'SBUX', 'AMGN', 'CHTR', 'GILD', 'CMCSA', 'BKNG', 'MDLZ', 'FISV', 'BIIB', 'MU', 'MCD', 'AMAT', 'ADP', 'ILMN', 'ATVI', 'ISRG', 'ADSK', 'LRCX', 'BIDU', 'JD', 'REGN', 'WBA', 'VRTX', 'KHC', 'WMT', 'ZM', 'MELI', 'TMUS', 'CTSH', 'XLNX', 'PCAR', 'ALGN', 'WDAY', 'SIRI', 'CTXS', 'ADI', 'EXC', 'LULU', 'MAR', 'KLAC', 'PAYX', 'EA', 'ILMN', 'ALXN', 'MNST', 'BMRN', 'EBAY', 'CTAS', 'VRSK', 'IDXX', 'CDNS', 'NXPI', 'ASML', 'INCY', 'KLAC', 'MCHP', 'SNPS', 'SWKS', 'VRSN', 'WDC', 'WYNN', 'XLNX', 'ZBRA', 'ZTS', 'AEP', 'AIG', 'ALL', 'AXP', 'BA', 'BAC', 'BK', 'BLK', 'C', 'CAT', 'CL', 'COF', 'COP', 'COST', 'CSCO', 'CVS', 'CVX', 'DD', 'DHR', 'DIS', 'DOW', 'DUK', 'EMR', 'EXC', 'F', 'FDX', 'GD', 'GE', 'GILD', 'GM', 'GOOG', 'GOOGL', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'JPM', 'KHC', 'KMI', 'KO', 'LLY', 'LMT', 'LOW', 'MA', 'MCD', 'MDLZ', 'MDT', 'MET', 'MMM', 'BLND', 'BLNG', 'BLNKW', 'BLNGU', 'BLNGW', 'BLNK', 'BLPH', 'BLRX', 'BLTE', 'BLU', 'BLUA', 'BLUE', 'BLW', 'BLX', 'BLZE', 'BMA', 'BMAC', 'BMAQ', 'BMAQR', 'BMAQU']\n",
      "File /share/us-stock-dataset/Data/Stocks/XLNX.csv not found\n",
      "File /share/us-stock-dataset/Data/Stocks/CTXS.csv not found\n",
      "File /share/us-stock-dataset/Data/Stocks/ALXN.csv not found\n",
      "File /share/us-stock-dataset/Data/Stocks/XLNX.csv not found\n",
      "File /share/us-stock-dataset/Data/Stocks/BLNKW.csv not found\n",
      "File /share/us-stock-dataset/Data/Stocks/BLNGU.csv not found\n",
      "File /share/us-stock-dataset/Data/Stocks/BLNGW.csv not found\n",
      "File /share/us-stock-dataset/Data/Stocks/BMAQ.csv not found\n",
      "File /share/us-stock-dataset/Data/Stocks/BMAQR.csv not found\n",
      "File /share/us-stock-dataset/Data/Stocks/BMAQU.csv not found\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mTimeseriesDataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstocks_to_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_diff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/Transformers1/timeseries/timeseries_transformer.py:126\u001b[0m, in \u001b[0;36mTimeseriesDataloader.__init__\u001b[0;34m(self, directory_path, stocks_to_load, my_device, add_diff)\u001b[0m\n\u001b[1;32m    121\u001b[0m df, found_files \u001b[38;5;241m=\u001b[39m read_and_merge_csv_files(directory_path, stocks_to_load, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2000-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    122\u001b[0m                                            end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2020-12-31\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    124\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 126\u001b[0m prices \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmy_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m prices_diff \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdiff(prices, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_diff:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:247\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    246\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 247\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    251\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "dataloader = TimeseriesDataloader(directory_path, stocks_to_load, add_diff=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d73344-4be7-48b2-9680-54259b4845c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=dataloader.get_data().transpose(0, 1).cuda()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb546f66-4233-4ccf-962f-a4d0808b9e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = torch.diff(data, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd64f4c-e94d-4677-bb55-553e56dfa2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.std(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87424453-f368-4439-9c70-0bb5441f3301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaling(tensor):\n",
    "    return (tensor - tensor.min()) / (tensor.max() - tensor.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ff39c6c-4215-461c-82f0-354e0424be87",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_data \u001b[38;5;241m=\u001b[39m min_max_scaling(\u001b[43mtraining_data\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(training_data\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_data' is not defined"
     ]
    }
   ],
   "source": [
    "training_data = min_max_scaling(training_data)\n",
    "print(training_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2d92649-d0dc-411c-a9bb-15f9fafbc8b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     windows \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39munfold(\u001b[38;5;241m1\u001b[39m, window_size, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m windows\n\u001b[0;32m----> 7\u001b[0m sliding_windows\u001b[38;5;241m=\u001b[39mextract_sliding_windows(\u001b[43mtraining_data\u001b[49m, window_size)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(sliding_windows\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_data' is not defined"
     ]
    }
   ],
   "source": [
    "window_size = 10\n",
    "\n",
    "def extract_sliding_windows(tensor, window_size):        \n",
    "    windows = tensor.unfold(1, window_size, 1)\n",
    "    return windows\n",
    "\n",
    "sliding_windows=extract_sliding_windows(training_data, window_size)\n",
    "\n",
    "print(sliding_windows.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "903c852d-88da-4fd9-a313-bb91bd7fd8b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sliding_windows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m flat_sliding_windows \u001b[38;5;241m=\u001b[39m \u001b[43msliding_windows\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, sliding_windows\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(flat_sliding_windows\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sliding_windows' is not defined"
     ]
    }
   ],
   "source": [
    "flat_sliding_windows = sliding_windows.reshape(-1, sliding_windows.size(2))\n",
    "print(flat_sliding_windows.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69510aa7-c9fb-42e8-a790-8abb2813cb4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flat_sliding_windows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mflat_sliding_windows\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mstd()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'flat_sliding_windows' is not defined"
     ]
    }
   ],
   "source": [
    "flat_sliding_windows.squeeze(1).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b60cbdd-1b54-4e72-9235-96bdd9a6cc6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TransformerConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mKarpathyTransformerModel\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config: TransformerConfig):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m, in \u001b[0;36mKarpathyTransformerModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mKarpathyTransformerModel\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config: \u001b[43mTransformerConfig\u001b[49m):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TransformerConfig' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "class KarpathyTransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, config: TransformerConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.token_embedding_table = nn.Embedding(config.vocab_size, config.n_embed)\n",
    "\n",
    "        # self.pos_emb1 = PositionalEmbedding(config)\n",
    "        # self.pos_dist_emb = DistancePositionalEmbedding(config)\n",
    "        self.pos_ffwd = GeluFeedForward(config.n_embed * 3, config.n_embed, config.n_embed * 2, config.dropout)\n",
    "        self.pos_ln = nn.LayerNorm(config.n_embed * 2)\n",
    "\n",
    "        self.blocks = BlockSequence(config)\n",
    "        self.ln_f = nn.LayerNorm(config.n_embed)  # final layer norm\n",
    "        self.lm_head = nn.Linear(config.n_embed, config.vocab_size)\n",
    "\n",
    "    def forward_vs_target(self, idx, targets):\n",
    "        logits = self.forward(idx)\n",
    "\n",
    "        b, t, c = logits.shape\n",
    "        logits_view = logits.view(b * t, c)\n",
    "        targets = targets.view(b * t)\n",
    "        loss = F.cross_entropy(logits_view, targets)\n",
    "\n",
    "        return logits_view, loss\n",
    "\n",
    "    def forward(self, idx):\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx)  # (B,T,C)\n",
    "\n",
    "        x = tok_emb # + pos_emb  # (B,T,C)\n",
    "        b, t, c = x.shape\n",
    "\n",
    "        pos_dist_emb = None #self.pos_dist_emb(b)\n",
    "\n",
    "        pos_emb = None #self.pos_emb1(b, t)\n",
    "\n",
    "        # pos_emb = torch.cat([pos_emb_dist, pos_emb], dim=-1)\n",
    "        #\n",
    "        # pos_emb = self.pos_ffwd(pos_emb)\n",
    "        #\n",
    "        # pos_emb = self.pos_ln(pos_emb)\n",
    "        # pos_emb = pos_emb_dist + pos_emb\n",
    "\n",
    "        # x, st_pos_emb = self.blocks(x, pos_emb)  # (B,T,C)\n",
    "        x, st_pos_emb = self.blocks(x, pos_emb, pos_dist_emb)  # (B,T,C)\n",
    "\n",
    "        x = self.ln_f(x)  # (B,T,C)\n",
    "        logits = self.lm_head(x)  # (B,T,vocab_size)\n",
    "        return logits\n",
    "\n",
    "dataloader = TimeseriesDataloader(directory_path, stocks_to_load)\n",
    "config = TimeseriesTransformerConfig(\n",
    "    batch_size=32,\n",
    "    block_size=512,\n",
    "    n_embed=32,\n",
    "    n_head=4,\n",
    "    n_layer=8,\n",
    "    kernel_size=1,\n",
    "    learning_rate=1e-3,\n",
    "    channels=dataloader.get_number_of_channels()\n",
    ")\n",
    "model = KarpathyTransformerModel(config)\n",
    "trainer1 = EnhancedKarpathyRunner(config, dataloader=dataloader, model=model)\n",
    "\n",
    "trainer1.train_eval(20000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e4938-6b65-4288-be06-5c2ccb49e271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
