{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4799c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from t3_karpathy.compressing_transformer import CompressingAccumulativeTrainer\n",
    "from t3_karpathy.transformer_config import TransformerConfig\n",
    "from t3_karpathy.gpt_nano_dataloader import GptNanoDataloader\n",
    "from t3_karpathy.karpathy_transformer import KarpathyRunner\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da801ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already downloaded\n",
      "in_size=32, in_embd=64, out_size=16, out_embd=64\n",
      "in_size=16, in_embd=64, out_size=8, out_embd=64\n",
      "in_size=8, in_embd=64, out_size=16, out_embd=64\n",
      "in_size=16, in_embd=64, out_size=32, out_embd=64\n",
      "0.414218 M parameters\n",
      "step 0: train loss 19.4401, val loss 19.3603\n",
      "step 100: train loss 3.4722, val loss 3.5389\n",
      "step 200: train loss 3.4004, val loss 3.4616\n",
      "step 300: train loss 3.3476, val loss 3.4013\n",
      "step 400: train loss 2.8272, val loss 2.8757\n",
      "step 500: train loss 2.6096, val loss 2.6441\n",
      "step 600: train loss 2.5181, val loss 2.5486\n",
      "step 700: train loss 2.4907, val loss 2.5196\n",
      "step 800: train loss 2.4729, val loss 2.5009\n",
      "step 900: train loss 2.4645, val loss 2.4856\n",
      "step 1000: train loss 2.4444, val loss 2.4690\n",
      "step 1100: train loss 2.4349, val loss 2.4545\n",
      "step 1200: train loss 2.4280, val loss 2.4519\n",
      "step 1300: train loss 2.4177, val loss 2.4375\n",
      "step 1400: train loss 2.4047, val loss 2.4230\n",
      "step 1500: train loss 2.3910, val loss 2.4102\n",
      "step 1600: train loss 2.3716, val loss 2.3942\n",
      "step 1700: train loss 2.3638, val loss 2.3822\n",
      "step 1800: train loss 2.3529, val loss 2.3702\n",
      "step 1900: train loss 2.3430, val loss 2.3612\n",
      "step 2000: train loss 2.3360, val loss 2.3519\n",
      "step 2100: train loss 2.3299, val loss 2.3498\n",
      "step 2200: train loss 2.3131, val loss 2.3346\n",
      "step 2300: train loss 2.3041, val loss 2.3213\n",
      "step 2400: train loss 2.2913, val loss 2.3109\n",
      "step 2500: train loss 2.2803, val loss 2.2991\n",
      "step 2600: train loss 2.2612, val loss 2.2826\n",
      "step 2700: train loss 2.2447, val loss 2.2658\n",
      "step 2800: train loss 2.2223, val loss 2.2431\n",
      "step 2900: train loss 2.2100, val loss 2.2311\n",
      "step 3000: train loss 2.1974, val loss 2.2206\n",
      "step 3100: train loss 2.1813, val loss 2.2044\n",
      "step 3200: train loss 2.1699, val loss 2.1921\n",
      "step 3300: train loss 2.1520, val loss 2.1709\n",
      "step 3400: train loss 2.1339, val loss 2.1554\n",
      "step 3500: train loss 2.1117, val loss 2.1339\n",
      "step 3600: train loss 2.0939, val loss 2.1216\n",
      "step 3700: train loss 2.0839, val loss 2.1064\n",
      "step 3800: train loss 2.0690, val loss 2.0941\n",
      "step 3900: train loss 2.0668, val loss 2.0896\n",
      "step 4000: train loss 2.0569, val loss 2.0827\n",
      "step 4100: train loss 2.0520, val loss 2.0779\n",
      "step 4200: train loss 2.0471, val loss 2.0677\n",
      "step 4300: train loss 2.0409, val loss 2.0646\n",
      "step 4400: train loss 2.0397, val loss 2.0621\n",
      "step 4500: train loss 2.0323, val loss 2.0536\n",
      "step 4600: train loss 2.0280, val loss 2.0526\n",
      "step 4700: train loss 2.0237, val loss 2.0446\n",
      "step 4800: train loss 2.0180, val loss 2.0430\n",
      "step 4900: train loss 2.0181, val loss 2.0394\n",
      "\n",
      " \n",
      "euo  aoWd yfgtratniwoq;woe,or lsi ewtlo\n",
      "we\n",
      "au,aaa\n",
      "apshEn\n",
      "ls tIdo;e i   oatwrtTns eslec rtsw t,ep a\n",
      "\n",
      "\n",
      "unrwrhporg niecrurU Nuiee\n",
      "knr  m:n Noc w easrFltr,Edrs  lTu tarh ids w\n",
      " rswL\n",
      "dolo iy neofr Ely hte,r\n",
      "ltnhratv anshaa\n",
      "leeEbnb Ie  te ssetfaosw ont .lrheg tse likvt\n",
      "o r;dfnHu 'wdTuiulP waunrty, s\n",
      "n\n",
      "l neln erioenaadrheusAsyenbeN\n",
      "rvsoI harTaibIat\n",
      "hereuImlIrIm bs .tc Bnf lnti  rg hetlaiml vtec  ree \n",
      "  da ele  aaeY,r,mph hst b aawtr,m.Dh;tdr nei tie'elo,bn  l  tdslr oT,ottl re he:rmiorsat  aead niliM  EthweWrn?mboelpKh t:e yrrvl:,s u maoide :Eiuoereigdhhinkp ru,Pt\n",
      "h \n",
      ",\n",
      "gTi,ig.hweu\n",
      "e:oBot,uds,hoHrhyJ rs   de\n",
      "Ihmirnm\n",
      "'yhmcFnnespnohtad l ct:g\n",
      "e jr:gtsKlIIv  Mdhdrtehw  ansr\n",
      "o Isyy asCy Bcrs dodsi :r ynirussh\n",
      "aMdlla\n",
      "t\n",
      " e,cubel ddnnudyi sHeaIsnhegi nwAn :dgE eosmaur\n",
      "\n",
      "vt:ndt:rIh ma  hHei,v\n",
      " ta ehinereea  e\n",
      "dnDt u\n",
      "aVsrttfsnlHboMnt\n",
      " mo h'vfr\n",
      "iafcB  won  mhlinr eo-iofet:pt,sUo elnnN Y'oe\n",
      ":ir tulOht,igu etnullehn poeiAua l  rOgeo  l1 r  nae nl E  \n",
      "fd n.r rs egIdek  N h ethkb Tooe\n",
      "nn reiddtai ooinyndhUwtuednraasldunhdymyeafuhraenmaay\n",
      "a ca e'c VcpassI am\n",
      " ilutni ,soete,A,eadsmoidhi\n",
      "rlerlg\n",
      "ro:uavoteu:\n",
      "odluluS ahlwarrEg  fN iegllrsl gss:m sol?lls  o:Oovdyeoth iotcdsodK. thlrhfacr au:ehyE\n",
      "hcn\n",
      "ihla inweeh weTmttyedth  oesetyeytnyr i iyKte  b iakc .\n",
      "yo.n\n",
      "et rufeh,eaiwinth\n",
      "uIno m s ftol\n",
      " ymt\n",
      "u ecirPO anfiu?tmuae  huy :eltwta owop \n",
      "hd s  esonl\n",
      ".eaertse woUde;a saa sauoigstte\n",
      "mMoeIsyhuO  .dH,  iOdy. aho lyehUdspnyn   Adrsinlons    htoi un rm\n",
      "clmiyeeoelsa -  u,e oENioglsrlnnmteh \n",
      "e eoriah\n",
      "a rnifn afAc\n",
      "aItnlsf o,me otur t,esCe\n",
      "\n",
      "ao,  tellh dinu\n",
      "es\n",
      "I:heauilloywnlfr oiW A,siI -e\n",
      ",raws hrdhh to S m\n",
      " \n",
      "rNy.iaeidHer Thoo\n",
      "; wthepwdnW Eoai\n",
      ";rseope fEr :ok\n",
      "tyay d,p l rGyr dsspxekewgnlcioa;afga :rtansasl nttsdrsheeuikwdlOdavr\n",
      "OLsoeo\n",
      "RiyUoe  lOesd!Rt\n",
      "akyaooodma.t?k ettd ,sdpNftoym wooce aN\n",
      "ytaoto rweoisddto\n",
      "t\n",
      " o\n",
      "Aa!rirWueG  h,Rltronoeotls e :nT mes \n",
      " sy rypeunlna !s vltiueena reohTD ir\n",
      "U:nO iw'a liE\n",
      "lnT  Emapr'dlr  igsdl\n",
      " eskfcbu:t hhiouar dw,iiu yhiEr\n",
      "Myylet;,hvuulasleecestew\n",
      "I\n",
      "!u ndRFkiReel fhaw:Ihae,vYhlh \n",
      ":et p;yt ne droonfieh tr uhotEiaroeven,,Tla   auo hV\n",
      "er av,oi o:rsudotlUtw r cnslAmgiEinoTs d\n",
      "O,,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = TransformerConfig()\n",
    "dataloader = GptNanoDataloader(config)\n",
    "device = 'cuda'\n",
    "\n",
    "trainer1=CompressingAccumulativeTrainer(config)\n",
    "#rainer1=KarpathyRunner(config)\n",
    "trainer1.train_iterate(5000, dataloader.get_train_batch, dataloader.get_val_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f52b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eEeeho  wde s i an BrBehesiKT sdto lEemyhdh:h\n",
      "rbdite:t s\n",
      "YibI ip sR t?yowa orlsamle r meobenW c\n",
      "Pto nh,o\n",
      "A yhuu  uha,ryoo o\n",
      "\n",
      "kl sf he: esywnr  lm !puf,Ia-n  e.msdib\n",
      "nd\n",
      "rosee ahrIoUE\n",
      "RnhltccBMlh hasb ro   engiewhe nls\n",
      "de\n",
      "b aeOkUEedirxhye hleoevInl\n",
      "\n",
      "dwralusnuoieugInknr:e,rf  bnaiae gl\n",
      "hn r sn\n",
      "o  ttdPnsoho sluo kr cw\n",
      "e\n",
      "mo nmeS rmytoMm  .nat\n",
      "db nt onT nUuuO.Irloo:l LnKoiu snhsdfhlpns feti strsdsoro\n",
      "noLb\n",
      "fr  n.isMofsto :se Ucn sle,\n",
      "synT to ,oh ibenpon'wohmhs,e   utso;L arsAlthrl y rs c Of seante  NabtIin a Ea,uiad  ered he n muthpsa  p,yheEhowmrh  UA  \n",
      "y uluyheL oT'oveo hvS a,o,wp\n",
      "t oood kt ds\n",
      "wdotmnffefasoySlrie W  m tp a\n",
      "l o, seIu.\n",
      "df\n",
      "-meonu ,htd e'\n",
      " nr  ebiel o ,ne n ns geonfeenmeVpgtst T, a,coasg eeqmetabtagt? ruurIeo s e\n",
      "rh -rm:or ireosahhs ohbrdooly,ftrap.ka d ol,efAuaCsCm,lamn dAoserteIrv   ,pctCu o ib\n",
      "otuIsndoeoa\n",
      "kh\n",
      " pgesgftsMecneatiosrnt ug lg h haeniseu  hhcgiiif.dwwriesya l amIina \n",
      "hd,iE ivabs ,a sUad  o,tdn\n",
      "r:rasaRAl ue wfttdh,oensmo aTrnWtna  rhbeN eVmh eowltifdaie\n",
      "uul: i v vf \n",
      "iIHuWiO lesosg\n",
      "\n",
      "ih'a,orro:ooyhger \n",
      " Irehowihthr\n",
      "iGon \n",
      "\n",
      "Tnpuuwndnh\n",
      "tmuh,?i Wi :hAts e nwh nsTdeaereaYgllaenetoTOn''elHMpn  lVoeeaeNairld  f tpett'ebs\n",
      "nsreIuoumeial;aaOohe hyht hs\n",
      "cpru fliot rddteCnn Fa w\n",
      "Soeioerdfeyhtcgncoah trhwaoioghtht? rinsi f dsmua\n",
      "i eesiflr'nbhe dylHiyilstvT lhogHYt reuisodit shoyaRfdwrcr yt yinrs.u ndi:ivohgnwe nnn nyntd Ta ene ' alps u eRn\n",
      ":rum :RBcswlrisjdi ee E.gInec w,ena  rywkwe iyhovllWhA te'daeieiw ,\n",
      "ddtkossoiaenr,egN.\n",
      "g.ernbaho  Crl   :tsmerhwknlt wew lIs lear t hnrauSka:-eh ismeet',twAs,nlov:xnptf'rahitree  ahl o  ue\n",
      "s  u \n",
      "oyldsuesae hEe  u:?ot ysntoserH!swe lnd el:i hft ohGalder   peoosRende ,lshhisyc,adfaoy nr ccl 'mnnlahdttsiss d Ut,oeefnty\n",
      " w  k\n",
      "mmBhhien fmc \n",
      "?ew \n",
      " Edn l\n",
      "mrOo,oeinAy i\n",
      "ts cshtosA\n",
      "taennhaa h\n",
      "oahg\n",
      "emy hh r svotcm:at r\n",
      "nid g anGdlRrtO\n",
      "ntn\n",
      "of\n",
      "rIsyI\n",
      ",ohie \n",
      "so, oovusli  . rMwslhso:wamldIseRo sys ,h neltdImrsa sunn\n",
      "ntclV wdt.oseSTn eirs .w\n",
      ",. neBHT tf Ier shIdootlveRht ArWarImeri hye  :aisslah sooiorhvTrkK yyesnlE,e ons:eDsse\n",
      "\n",
      "esyoohg  oo:o\n"
     ]
    }
   ],
   "source": [
    "#print(dataloader.token_codec.decode(trainer1.generate(torch.zeros((1, 1), dtype=torch.long, device=device), 100)[0].tolist()))\n",
    "context = torch.zeros((32, 1), dtype=torch.long, device=device)\n",
    "print(dataloader.token_codec.decode(trainer1.generate(context, max_new_tokens=2000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86b60f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "oeut g obUWdnwueeheae\n",
      ".m a u\n",
      "s:inelr LoO ,e lu tsnoa\n",
      "n;apdwrifCmpniI\n",
      "' hFth \n",
      "dwiOhed rioowT\n",
      "isN,sewn\n"
     ]
    }
   ],
   "source": [
    "print(dataloader.token_codec.decode(trainer1.generate(torch.zeros((32, 1), dtype=torch.long, device=device), 100)[0].tolist()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}