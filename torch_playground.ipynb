{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4799c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from t3_karpathy.compressing_transformer import CompressingAccumulativeTrainer\n",
    "from t3_karpathy.transformer_config import TransformerConfig\n",
    "from t3_karpathy.gpt_nano_dataloader import GptNanoDataloader\n",
    "from t3_karpathy.karpathy_transformer import KarpathyRunner\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0ee2c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already downloaded\n",
      "in_size=32, in_embd=64, out_size=16, out_embd=64\n",
      "in_size=16, in_embd=64, out_size=8, out_embd=64\n",
      "in_size=8, in_embd=64, out_size=16, out_embd=64\n",
      "in_size=16, in_embd=64, out_size=32, out_embd=64\n",
      "0.414218 M parameters\n",
      "step 0: train loss 15.9134, val loss 15.9326\n",
      "step 100: train loss 3.5526, val loss 3.5994\n",
      "step 200: train loss 3.4700, val loss 3.5172\n",
      "step 300: train loss 3.4212, val loss 3.4761\n",
      "step 400: train loss 3.3716, val loss 3.4224\n",
      "step 500: train loss 3.3541, val loss 3.3911\n",
      "step 600: train loss 3.3390, val loss 3.3761\n",
      "step 700: train loss 3.3235, val loss 3.3652\n",
      "step 800: train loss 3.2723, val loss 3.3054\n",
      "step 900: train loss 3.1570, val loss 3.1782\n",
      "step 1000: train loss 2.6906, val loss 2.7285\n",
      "step 1100: train loss 2.5814, val loss 2.6122\n",
      "step 1200: train loss 2.5668, val loss 2.5776\n",
      "step 1300: train loss 2.5437, val loss 2.5688\n",
      "step 1400: train loss 2.5383, val loss 2.5566\n",
      "step 1500: train loss 2.5172, val loss 2.5416\n",
      "step 1600: train loss 2.5017, val loss 2.5201\n",
      "step 1700: train loss 2.4843, val loss 2.5118\n",
      "step 1800: train loss 2.4776, val loss 2.4979\n",
      "step 1900: train loss 2.4730, val loss 2.4975\n",
      "step 2000: train loss 2.4585, val loss 2.4765\n",
      "step 2100: train loss 2.4538, val loss 2.4726\n",
      "step 2200: train loss 2.4409, val loss 2.4592\n",
      "step 2300: train loss 2.4241, val loss 2.4374\n",
      "step 2400: train loss 2.4227, val loss 2.4451\n",
      "step 2500: train loss 2.4184, val loss 2.4397\n",
      "step 2600: train loss 2.4068, val loss 2.4275\n",
      "step 2700: train loss 2.4033, val loss 2.4226\n",
      "step 2800: train loss 2.3894, val loss 2.4121\n",
      "step 2900: train loss 2.3870, val loss 2.4115\n",
      "step 3000: train loss 2.3822, val loss 2.3998\n",
      "step 3100: train loss 2.3810, val loss 2.4063\n",
      "step 3200: train loss 2.3782, val loss 2.3943\n",
      "step 3300: train loss 2.3729, val loss 2.3930\n",
      "step 3400: train loss 2.3678, val loss 2.3924\n",
      "step 3500: train loss 2.3743, val loss 2.3852\n",
      "step 3600: train loss 2.3621, val loss 2.3757\n",
      "step 3700: train loss 2.3616, val loss 2.3735\n",
      "step 3800: train loss 2.3599, val loss 2.3810\n",
      "step 3900: train loss 2.3530, val loss 2.3731\n",
      "step 4000: train loss 2.3380, val loss 2.3575\n",
      "step 4100: train loss 2.3370, val loss 2.3599\n",
      "step 4200: train loss 2.3297, val loss 2.3427\n",
      "step 4300: train loss 2.3313, val loss 2.3525\n",
      "step 4400: train loss 2.3326, val loss 2.3594\n",
      "step 4500: train loss 2.3304, val loss 2.3543\n",
      "step 4600: train loss 2.3317, val loss 2.3428\n",
      "step 4700: train loss 2.3266, val loss 2.3458\n",
      "step 4800: train loss 2.3160, val loss 2.3336\n",
      "step 4900: train loss 2.3208, val loss 2.3401\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 1 but got size 32 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_12216/2016361936.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[0mtrainer1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_iterate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m5000\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdataloader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_train_batch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdataloader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_val_batch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataloader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtoken_codec\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrainer1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgenerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlong\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m100\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[0mcontext\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlong\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\workspace\\ai\\Transformers1\\ga_t3\\accumulative_trainer.py\u001B[0m in \u001B[0;36mgenerate\u001B[1;34m(self, idx, max_new_tokens)\u001B[0m\n\u001B[0;32m     34\u001B[0m             \u001B[0midx_next\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmultinomial\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprobs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_samples\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# (B, 1)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     35\u001B[0m             \u001B[1;31m# append sampled index to the running sequence\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 36\u001B[1;33m             \u001B[0midx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0midx_next\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# (B, T+1)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     37\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0midx\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Sizes of tensors must match except in dimension 1. Expected size 1 but got size 32 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "\n",
    "config = TransformerConfig()\n",
    "dataloader = GptNanoDataloader(config)\n",
    "device = 'cuda'\n",
    "\n",
    "trainer1=CompressingAccumulativeTrainer(config)\n",
    "#rainer1=KarpathyRunner(config)\n",
    "trainer1.train_iterate(5000, dataloader.get_train_batch, dataloader.get_val_batch)\n",
    "\n",
    "print(dataloader.token_codec.decode(trainer1.generate(torch.zeros((1, 1), dtype=torch.long, device=device), 100)[0].tolist()))\n",
    "\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(dataloader.token_codec.decode(trainer1.generate(context, max_new_tokens=2000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed90eb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 1 but got size 32 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_12216/859749116.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mcontext\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlong\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataloader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtoken_codec\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrainer1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgenerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcontext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_new_tokens\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m2000\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mF:\\workspace\\ai\\Transformers1\\ga_t3\\accumulative_trainer.py\u001B[0m in \u001B[0;36mgenerate\u001B[1;34m(self, idx, max_new_tokens)\u001B[0m\n\u001B[0;32m     34\u001B[0m             \u001B[0midx_next\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmultinomial\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprobs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_samples\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# (B, 1)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     35\u001B[0m             \u001B[1;31m# append sampled index to the running sequence\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 36\u001B[1;33m             \u001B[0midx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0midx_next\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# (B, T+1)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     37\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0midx\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Sizes of tensors must match except in dimension 1. Expected size 1 but got size 32 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "\n",
    "#print(dataloader.token_codec.decode(trainer1.generate(torch.zeros((1, 1), dtype=torch.long, device=device), 100)[0].tolist()))\n",
    "\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(dataloader.token_codec.decode(trainer1.generate(context, max_new_tokens=2000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c11043a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 1 but got size 32 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_12216/634803848.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataloader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtoken_codec\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrainer1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgenerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlong\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m100\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mF:\\workspace\\ai\\Transformers1\\ga_t3\\accumulative_trainer.py\u001B[0m in \u001B[0;36mgenerate\u001B[1;34m(self, idx, max_new_tokens)\u001B[0m\n\u001B[0;32m     34\u001B[0m             \u001B[0midx_next\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmultinomial\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprobs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_samples\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# (B, 1)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     35\u001B[0m             \u001B[1;31m# append sampled index to the running sequence\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 36\u001B[1;33m             \u001B[0midx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0midx_next\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# (B, T+1)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     37\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0midx\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Sizes of tensors must match except in dimension 1. Expected size 1 but got size 32 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "print(dataloader.token_codec.decode(trainer1.generate(torch.zeros((1, 1), dtype=torch.long, device=device), 100)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e0e9dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bca;S;A:d Im uhOehwhtohortrrt rn'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer1.predict(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75953974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5368605",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_12216/2545225024.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     10\u001B[0m     \u001B[0mlogits\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlogits\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m  \u001B[1;31m# becomes (B, C)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m     \u001B[1;31m# apply softmax to get probabilities\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m     \u001B[0mprobs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msoftmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlogits\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# (B, C)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m     \u001B[1;31m# sample from the distribution\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m     \u001B[0midx_next\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmultinomial\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprobs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_samples\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# (B, 1)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "idx=torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "block_size = 32\n",
    "max_new_tokens=100\n",
    "for _ in range(max_new_tokens):\n",
    "    # crop idx to the last block_size tokens\n",
    "    idx_cond = idx[:, -block_size:]\n",
    "    # get the predictions\n",
    "    logits = trainer1.runner.forward(idx_cond)\n",
    "    # focus only on the last time step\n",
    "    logits = logits[:, -1, :]  # becomes (B, C)\n",
    "    # apply softmax to get probabilities\n",
    "    probs = F.softmax(logits, dim=-1)  # (B, C)\n",
    "    # sample from the distribution\n",
    "    idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "    # append sampled index to the running sequence\n",
    "    idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
    "return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ead2710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}